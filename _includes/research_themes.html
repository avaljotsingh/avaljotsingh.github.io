<h2>Research Themes</h2>

<!-- ========== Formal Methods for AI ========== -->
<h3>Formal Methods for AI</h3>

<p>This line of work focuses on building principled and trustworthy neural network analysis and certification systems using formal methods. My goal is to make neural network certifiers easier to design, mechanically verifiable for soundness, and efficient to execute, by providing a unified infrastructure spanning specification, verification, and compilation.</p>

{%- for project in site.data.research_projects.fm_for_ai.projects -%}
  {%- include research_project_card.html project=project -%}
{%- endfor -%}

<!-- ========== AI for Formal Methods ========== -->
<h3>AI for Formal Methods</h3>

<p>This line of work investigates how machine learning and program synthesis techniques can be used to automate and scale formal methods. My focus is on using AI to generate, improve, and adapt formal analysis tools and reasoning procedures, reducing the manual effort traditionally required to design and tune verification systems.</p>

{%- for project in site.data.research_projects.ai_for_fm.projects -%}
  {%- include research_project_card.html project=project -%}
{%- endfor -%}

<!-- ========== Other Research ========== -->
<h3>Other Research</h3>

<p>Additional work that does not sit directly under the two main themes is grouped under <a href="{{ '/publications/' | relative_url }}#other">Other research</a> on the <a href="{{ '/publications/' | relative_url }}">Publications</a> page: e.g. <strong>Syndicate</strong> (synergistic synthesis of ranking functions and invariants for termination), <strong>AgentRx</strong> (diagnosing AI agent failures from execution trajectories), and <strong>ProFIt</strong> (interpreting robustness proofs of deep neural networks).</p>
