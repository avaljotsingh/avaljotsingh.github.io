---
---


@article{constraintflowcompiler,
    abbr={ConstraintFlow},
	title={A Tensor-Based Compiler and a Runtime for Neuron-Level DNN Certifier Specifications},
	author={Singh, Avaljot and Sarita, Yasmin and Mishra, Aditya and Goyal, Ishaan and Singh, Gagandeep and Mendis, Charith},
	journal={Arxiv},
    html={https://arxiv.org/pdf/2507.20055},
	year={2025},
    selected=true
}

@article{syndicate,
    abbr={Syndicate},
	title={Syndicate: Synergistic Synthesis of Ranking Function and Invariants for Termination Analysis},
	author={Sarita, Yasmin and Singh, Avaljot and Gomber,Shaurya and Singh, Gagandeep and Vishwanathan, Mahesh},
	journal={Arxiv},
    html={https://arxiv.org/pdf/2404.05951},
	year={2025},
    selected=true
}

@article{nnverfication,
    abbr={Neural Network Verification},
	title={Safety and Trust in Artificial Intelligence with Abstract Interpretation},
	author={Singh, Gagandeep and Laurel, Jacob and Misailovic, Sasa and Banerjee, Debangshu and Singh, Avaljot and Xu, Changming and Ugare, Shubham and Zhang, Huan},
	journal={Foundations and Trends in Programming Languages},
    html={https://www.nowpublishers.com/article/Details/PGL-062},
	year={2025},
    selected=true
}

@article{provesound,
    abbr={ProveSound},
	title={Automated Verification of Soundness of DNN Certifiers},
	author={Singh, Avaljot and Sarita, Yasmin and Mendis, Charith and Singh, Gagandeep},
	year={2025},
	journal={OOPSLA},
    html={https://arxiv.org/pdf/2504.04542},
    selected=true
}

@inproceedings{constraintflow,
    abbr={ConstraintFlow},
    author={Singh, Avaljot and Sarita, Yasmin and Mendis, Charith and Singh, Gagandeep},
    title={	ConstraintFlow: A DSL for Specification and Verification of Neural Network Analyses},
    booktitle="Static Analysis",
    year="2024",
    publisher="Springer Nature Switzerland",
    html={https://link.springer.com/chapter/10.1007/978-3-031-74776-2_16},
    selected=true
}

@inproceedings{
    banerjee2024dissecting,
    abbr={ProFIt},
    title={Interpreting Robustness Proofs of Deep Neural Networks},
    abstract={In recent years numerous methods have been developed to formally verify the robustness of deep neural networks (DNNs). Though the proposed techniques are effective in providing mathematical guarantees about the DNNs' behavior, it is not clear whether the proofs generated by these methods are human understandable. In this paper, we bridge this gap by developing new concepts, algorithms, and representations to generate human understandable insights into the internal workings of DNN robustness proofs. Leveraging the proposed method, we show that the robustness proofs of standard DNNs rely more on spurious input features as compared to the proofs of DNNs trained to be robust. Robustness proofs of the provably robust DNNs filter out a larger number of spurious input features as compared to adversarially trained DNNs, sometimes even leading to the pruning of semantically meaningful input features. The proofs for the DNNs combining adversarial and provably robust training tend to achieve the middle ground.},
    author={Debangshu Banerjee and Avaljot Singh and Gagandeep Singh},
    booktitle={The Twelfth International Conference on Learning Representations (ICLR)},
    year={2024},
    url={https://openreview.net/forum?id=Ev10F9TWML},
    pdf={Profit.pdf},
    html={https://openreview.net/forum?id=Ev10F9TWML},
    selected=true
}

